{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glw8wiEqOQfe"
   },
   "source": [
    "# Final Project: 9. Analytical Thinking\n",
    "\n",
    "## 1) Choosing a data set (30 mins)\n",
    "For the upcoming project, you need to choose a data set. You could either choose your own data set, or use one of the three sets linked below. \n",
    "\n",
    "1.   **Data Set 1:** Stack Overflow survey for Germany 2022\n",
    "\n",
    "You may analyze the Annual Stack Overflow Developer Survey from 2022. It contains about 70,000 responses fielded from over 180 countries and ultimately provides an overview about the global developer community using Stack Overflow. The random sample cotains 20% of the original data set.\n",
    "\n",
    "- the random sample is available [here](https://raw.githubusercontent.com/ReDI-School/nrw-data-analytics/main/9_StackOverflowSurvey_Sample_random20percent.csv) - *recommended*\n",
    "- you can also download the full dataset [here](https://insights.stackoverflow.com/survey) - *very big*\n",
    "- get insights [here](https://survey.stackoverflow.co/2022/)\n",
    "\n",
    "-----------------\n",
    "\n",
    "2.   **Data Set 2:** Xinjiang Detention Centers\n",
    "\n",
    "You may analyze data on prisoners of the Xinjian region in China. Sincce the spring of 2017, China's Xinjiang Uyghur Autonomous Region has seen a drastic rise in the mass incarcerations of its ethnic minority citizens – most notably, the Uyghur, Kazakh, Kyrgyz, and Hui – with hundreds of thousands being locked up in detention centers. \n",
    "\n",
    "- you can download different data sets (deaths, camps...) [here](https://shahit.biz/eng/#lists) or  [here](https://xjdp.aspi.org.au/resources/xinjiangs-detention-facilities/)\n",
    "\n",
    "\n",
    "-----------------\n",
    "\n",
    "3.  **Data Set 3:** KiGGS longtitudinal study of childens health in Germany\n",
    "\n",
    "The KiGGS is a long-term study conducted y the Robert Koch institute to monitor the health of children, adolescents and young adults in Germany. Herefore, a mzltitude of factors that could influence a childs health and health outcomes are tracked.\n",
    "\n",
    "####-> DATA IS IN GERMAN! DESCRIPTION ALSO AVAILABLE IN ENGLISH!\n",
    "\n",
    "- dowload data [here](https://www.icloud.com/attachment/?u=https%3A%2F%2Fcvws.icloud-content.com%2FB%2FAQZWEVZl6Rbqfzi2cvOFkNqiOz1NATmff9gA-o9tC39z6AoIkxNODRFZ%2F%24%7Bf%7D%3Fo%3DAgtYIYANQR1jKX_JQUt9xBWGXn-9TqE-mjBt0R32QpSN%26v%3D1%26x%3D3%26a%3DCAogDFZ_030BtACfjKNn2Th44b0oMR2AiBJ8KAl72X-uoZYSdhDF_82Y0DAYxY_J7NkwIgEAKgkC6AMA_z4Bat1SBKI7PU1aBE4NEVlqJTXTfMuQze9vwIiTC6bX6fyMEHr8i3K8X2Z8LcK3p75FoexHaCFyJTXW-HyjsyJYt6eTnqyJX6DkOtaed9LRWB-TPtfiK17ZcN7iFTk%26e%3D1673385887%26fl%3D%26r%3DA5B367E6-5082-4387-BE82-F5C4065778DB-1%26k%3D%24%7Buk%7D%26ckc%3Dcom.apple.largeattachment%26ckz%3DD0CB4BD2-FD03-4686-9C71-782D43341A29%26p%3D34%26s%3DR8AMO5k1O0jqfOJo3YEJgGkYi8A&uk=3abPxkbaXmrY_zmj3G25ag&f=KiGGS03_06.sav&sz=26878994)\n",
    "- get insights [here](https://www.kiggs-studie.de/english/survey.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddAaJwVZQ46n"
   },
   "source": [
    "## 2) Analysis (120 mins)\n",
    "\n",
    "Step 1: **Set a Goal!** -> Think in terms of statistical plan. Look through the questions below, those are examples and references that may be a starting point for your analysis.\n",
    "\n",
    "**Stack Overflow Survey:**\n",
    "1.   What kind of information does the survey contain?\n",
    "2.   Which variables are particularly interesting to you and why? \n",
    "3. Analyze the salary and how different variables are correlating with it.\n",
    "\n",
    "**Prisoners & Detention Centers**\n",
    "1. Do the dataset reflect the same underlying processes i.e. do the missed person contribute to populate local prisons?\n",
    "2. Visualize the data according to time\n",
    "3. Calculate and/or visualize the data according to location (difficult).\n",
    "\n",
    "**Children's Health**\n",
    "1. Investigate blood levels of HbA1c which is a blood biomarker of blood sugar levels and therefore an indicator of diabetes\n",
    "2. Variables that might be associated are bmiB (body mass index), sex, age2 (sex) and the amount and frequency of eating chips (fq44/ fq44a)\n",
    "\n",
    "\n",
    "----------------------\n",
    "General questions:\n",
    "1. Descriptive statistics & graphs\n",
    "* What are the scales (nominal, ordinal, metric) of the variables that you want to analyze?\n",
    "* for each variable decide which descriptive statistic is best suited to describe it: (i) frequencies, (ii) mean/ standard deviation, (iii) deviation\n",
    "* indicate how many missing values each variable you analyze has\n",
    "*...\n",
    "2. Analysis \n",
    "* for example use linear regression or logistic regression\n",
    "* formulate a goal and hypothesis and test those\n",
    "*...\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Research Question: \n",
    "Does the blood sugar levels (HbA1c) in children impacted by the factors like BMI, gender, age and frequency of eating chips? \n",
    "\n",
    "\n",
    "Null Hypothesis (H0): There is a no significant relationship between the blood sugar levels (HbA1c) in children impact by BMI, gender, and age and frequency of eating chips. \n",
    "\n",
    "\n",
    "\n",
    "Alternative Hypothesis(H1) : There is a significant relationship between the blood sugar levels (HbA1c) in children impact by BMI, gender, and age and frequency of eating chips. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inh4STax2z6-"
   },
   "source": [
    "###**1) Import data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTg3bvIn2IOr"
   },
   "source": [
    "**a) Import from local storage after downloading csv from website**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1548,
     "status": "ok",
     "timestamp": 1670790765373,
     "user": {
      "displayName": "Ka Ba",
      "userId": "08277395367003334094"
     },
     "user_tz": -60
    },
    "id": "M1pSpjtx13nf",
    "outputId": "01378e7e-eaaa-4ece-d877-f90d3ac94e79"
   },
   "outputs": [],
   "source": [
    "# import libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data set \n",
    "\n",
    "path = '/Users/arunibandara/Downloads'\n",
    "df_3= pd.read_csv(os.path.join(path,'9_random_sample_KiGGS.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data set with relevent columns only necessary for the analysis\n",
    "\n",
    "# path = '/Users/arunibandara/Downloads'\n",
    "# df_3= pd.read_csv(os.path.join(path,'9_random_sample_KiGGS.csv'))\n",
    "\n",
    "url_3 = 'https://raw.githubusercontent.com/ReDI-School/nrw-data-analytics/main/9_KiGGS03_06.csv'\n",
    "df_3 =  pd.read_csv(url_3)\n",
    "print(df_3.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-nv1O567I4L"
   },
   "source": [
    "### Data Exploration\n",
    "\n",
    "\n",
    "*  see https://towardsdatascience.com/an-introduction-to-exploratory-data-analysis-in-python-9a76f04628b8 \n",
    "* see Lecture 6 - Exploratory Data Analysis [here](https://github.com/ReDI-School/nrw-data-analytics/blob/main/6_Lecture_More_Plots_and_intro_to_EDA_edited.ipynb)\n",
    "*   read the documentation of the dataset, if there is any!\n",
    "* If necessary, get rid of NAs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Security:The data set above has no security implications, since we couldnt identify any sensitive are names, email addresses, physical addresses, and phone numbers which we can trace back a person with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06ZznBu5uyPX"
   },
   "outputs": [],
   "source": [
    "df_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Li1m6iiYyrnS"
   },
   "outputs": [],
   "source": [
    "df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vsaHz445y1iL"
   },
   "outputs": [],
   "source": [
    "df_3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvXgBRAF0ZkV"
   },
   "outputs": [],
   "source": [
    "df_3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are columns contatining null values `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for null value percentages \n",
    "((df_3.isnull().sum() / len(df_3))*100).sort_values(ascending = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the null value percetages are below 50 % it is necessary and worth to consider handling null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vS9I7mCd2pnX"
   },
   "outputs": [],
   "source": [
    "df_3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cleaning data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.HbA1c.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for missing values \n",
    "# df_3.HbA1c.value_counts().sort_values(ascending = False)\n",
    "df_3.HbA1c.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.HbA1c.value_counts().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['HbA1c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['HbA1c'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['HbA1c'].fillna('Missing').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is the significant factor which decide the analysis main factor , better to consider deletion of missing data from HbA1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the HbA1c column \n",
    "\n",
    "df_3.dropna(subset=['HbA1c'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.HbA1c.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['HbA1c'].fillna('Missing').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking current missing values \n",
    "df_3.HbA1c.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for missing values in data set after handling HbA1c Column \n",
    "((df_3.isnull().sum() / len(df_3))*100).sort_values(ascending = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.isna().sum().sort_values(ascending = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling Frequency of eating chips coulumn with fq44a () \n",
    "df_3.fq44a.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping values as understadable way to calculate the propotion to find the fequency of eating chips\n",
    "\n",
    "# Mapping values from 'fq44a' to a new column 'chip_frequency'\n",
    "frequency_map = {\n",
    "    '1/4 Schale (oder weniger)': 1,\n",
    "    '2 Schalen': 8,\n",
    "    '1 Schale': 4,\n",
    "    '1/2 Schale': 2,\n",
    "    '3 Schalen (oder mehr)': 12,\n",
    "    'nie': 0,\n",
    "    'Unknown': 'Unknown'\n",
    "}\n",
    "\n",
    "# Creating a new column 'chip_frequency' by mapping values from 'fq44a'\n",
    "df_3['chip_amount'] = df_3['fq44a'].map(frequency_map)\n",
    "\n",
    "# Displaying the updated DataFrame with the new column 'chip_frequency'\n",
    "print(df_3[['fq44a', 'chip_amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['chip_amount'].fillna('Unknown').value_counts().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.fq44a.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the 'chip_amount' column with 0 - missing values are considered to be as they are never +nie eating chips\n",
    "df_3['chip_amount'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.chip_amount.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['chip_amount'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # handling Frequency of eating chips coulumn with fq44 () \n",
    "df_3.fq44 .unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping values as understadable way to calculate the propotion to find the fequency of eating chips\n",
    "\n",
    "# Handling missing values in 'fq44' column by filling NaN with 'Unknown'\n",
    "df_3['fq44'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Mapping values from 'fq44' to a new column 'chip_duration'\n",
    "frequency_map = {\n",
    "    '1 mal im Monat': 1/30,\n",
    "    '2-3 mal im Monat': 2.5/30,\n",
    "    '1-2 mal pro Woche': 1.5/7,\n",
    "    'Nie': 0,\n",
    "    '3-4 mal pro Woche': 3.5/7,\n",
    "    '1 mal am Tag': 1/1,\n",
    "    '5-6 mal pro Woche': 5.5/7,\n",
    "    '2-3 mal am Tag': 2.5/1,\n",
    "    '4-5 mal am Tag': 4.5/1,\n",
    "    'Öfter als 5 mal am Tag': 5/1,\n",
    "    'Unknown': 'Unknown'\n",
    "}\n",
    "\n",
    "# Creating a new column 'chip_frequency' by mapping values from 'fq44'\n",
    "df_3['chip_duration'] = df_3['fq44'].map(frequency_map)\n",
    "\n",
    "# Displaying the updated DataFrame with the new column 'chip_frequency'\n",
    "print(df_3[['fq44', 'chip_duration']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['chip_duration'].fillna('Unknown').value_counts().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the 'chip_duration' column with 0 - missing values are considered to be as they are never =nie eating chips in any time \n",
    "df_3['chip_duration'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.chip_duration.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Unknown' values in the 'chip_duration' column with 0\n",
    "df_3['chip_duration'].replace('Unknown', 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.chip_duration.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['chip_duration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the proportion between 'chip_amount' and 'chip_duration'\n",
    "df_3['chip_frequency'] = df_3['chip_amount'] / df_3['chip_duration']\n",
    "\n",
    "# Display the updated DataFrame with the proportion values\n",
    "print(df_3[['chip_amount', 'chip_duration', 'chip_frequency']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null value percentages final check :\n",
    "\n",
    "((df_3.isnull().sum() / len(df_3))*100).sort_values(ascending = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now data set values are acceptable and considered as data cleaning for missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for duplicates \n",
    "\n",
    "# Find duplicates\n",
    "\n",
    "df_3D= df_3[df_3.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows based on all columns\n",
    "df_3c = df_3[~df_3.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3c=df_3c[df_3.duplicated()]\n",
    "df_3c.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now no duplicates are found "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Unknown' values in the 'chip_duration' column with 0\n",
    "df_3['chip_frequency'].replace('NaN', 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3c ['chip_frequency'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3c.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of Gender analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.sex.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating analysis from mapping the gendaer vaue :\n",
    "\n",
    "# mapping values as understadable way in gender value :\n",
    "# Mapping values from 'fq44a' to a new column 'gender'\n",
    "frequency_map = {\n",
    "    'Männlich': 'M',\n",
    "    'Weiblich': 'F'   \n",
    "}\n",
    "\n",
    "# Creating a new column 'chip_frequency' by mapping values from 'fq44a'\n",
    "df_3['gender'] = df_3['sex'].map(frequency_map)\n",
    "\n",
    "# Displaying the updated DataFrame with the new column 'chip_frequency'\n",
    "print(df_3[['sex', 'gender']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.age2.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating analysis from mapping the age vaue :\n",
    "\n",
    "# mapping values as understadable way in age2 value :\n",
    "# Mapping values from 'age2' to a new column 't_age' considering upper limit of the age \n",
    "frequency_map = {\n",
    "    '12 - 13 J.': 13,\n",
    "    '10 - 11 J.': 11,\n",
    "     '8 - 9 J.' : 9,\n",
    "     '14 - 15 J.' :15,\n",
    "    '4 - 5 J.': 5,\n",
    "    '2 - 3 J.': 3,\n",
    "    '6 - 7 J.': 7,\n",
    "    '0 - 1 J.':1,\n",
    "    '16 - 17 J.' :17\n",
    "}\n",
    "\n",
    "# Creating a new column 'chip_frequency' by mapping values from 'fq44a'\n",
    "df_3['t_age'] = df_3['age2'].map(frequency_map)\n",
    "\n",
    "# Displaying the updated DataFrame with the new column 'chip_frequency'\n",
    "print(df_3[['age2', 't_age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['t_age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNROKehe23bX"
   },
   "source": [
    "### Analyze\n",
    "\n",
    "*“The basic general intent of data analysis is simply stated: to seek through a body of data for interesting relationships and information and to exhibit the results in such a way as to make them recognizable to the data analyzer and recordable for posterity\"* - J.W.Tukey \n",
    "\n",
    "* formulate a goal for your analysis\n",
    "* generate and answer hypothesis to test in order to reach that goal\n",
    "* create visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating correlation map \n",
    "# Create a correlation heatmap using matplotlib\n",
    "\n",
    "plt.matshow(df_3.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save figure\n",
    "plt.matshow(df_3.corr())\n",
    "plt.savefig(\"out.png\") \n",
    "\n",
    "# This will sbave the image in the working directory. \n",
    "#If you don't know what this directory is the next line will show you how to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current dir\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add labels, a legend, and change the size of the heatmap\n",
    "\n",
    "f = plt.figure(figsize=(8, 8)) # figure size \n",
    "plt.matshow(df_3.corr(), fignum=f.number) # type of plot\n",
    "plt.xticks(range(df_3.shape[1]), df_3.columns, fontsize=14, rotation=45) # x axis labels\n",
    "plt.yticks(range(df_3.shape[1]), df_3.columns, fontsize=14) # y axis labels\n",
    "cb = plt.colorbar() # add a colour legend (called colorbar)\n",
    "cb.ax.tick_params(labelsize=14) # add font size\n",
    "plt.title('Correlation Matrix', fontsize=14) # add title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pair plots \n",
    "\n",
    "# Create a pair plot \n",
    "\n",
    "g = sns.pairplot(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'/Users/arunibandara/Documents/ReDIDA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.to_csv(os.path.join(path, 'df_3_proper'),index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_3['chip_frequency'], bins = 20, kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of gender\n",
    "# Box plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='gender', y='HbA1c', data=df_3)\n",
    "plt.title('Gender vs HbA1c Levels')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('HbA1c Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age and HBA1c vale relation analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting bar chart \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df_3['t_age'], df_3['HbA1c'], color='skyblue')\n",
    "plt.title('Average HbA1c Values by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Average HbA1c Values')\n",
    "plt.xticks(rotation=45)  \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis in how HBA1c impact by Age_group and BMI value of children \n",
    "\n",
    "# Scatterplot matrix\n",
    "sns.pairplot(df_3[['HbA1c', 't_age', 'bmiB']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of each age\n",
    "age_counts = df_3['t_age'].value_counts().sort_index()\n",
    "\n",
    "# Bar plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(age_counts.index, age_counts.values, color='red')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Each Age')\n",
    "custom_values = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10','11','12','13','14','15','16','17','18']\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_3['t_age'], bins=20, color='blue')  # Adjust the number of bins as needed\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Age Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.loc[df_3['t_age'] < 5, 'age_group'] = 'toddler(0-5J)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.loc[(df_3['t_age'] >= 5) & (df_3['t_age'] < 13), 'age_group'] = 'Kids(5-13)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.loc[df_3['t_age'] >= 13, 'age_group'] = 'teens or older(13-18J)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['age_group'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['HbA1c'].value_counts().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['HbA1c'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = df_3['HbA1c'].min()\n",
    "max_value = df_3['HbA1c'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Value Range in '{'HbA1c'}': {min_value} to {max_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.loc[df_3['HbA1c'] < 3, 'possibility'] = 'low_pos(0-3)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.loc[(df_3['HbA1c']>= 3 )& (df_3['HbA1c']<5.7), 'possibility'] = 'miidle _pos(3-5.7)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.loc[(df_3['HbA1c'] >=5.7) & (df_3['HbA1c'] <=11), 'possibility'] = 'High_pos(5.7-10.8)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['possibility'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a categorical plot in seaborn using the price categories created above\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "plt.figure(figsize=(50,50))  # Adjust the figure size as needed (12 inches width, 6 inches height)\n",
    "g = sns.catplot(x=\"HbA1c\", y=\"bmiB\", hue=\"age_group\", data=df_3)\n",
    "\n",
    "# Define your desired intervals for x-axis ticks\n",
    "desired_intervals = []  # Modify these intervals as needed\n",
    "\n",
    "# Modify x-axis labels using Matplotlib\n",
    "plt.xticks(ticks=desired_intervals, labels=[f'{i}' for i in desired_intervals], rotation=45)\n",
    "\n",
    "# Expand x-axis by setting aspect ratio\n",
    "# plt.gca().set_aspect(1.5)  # Adjust the aspect ratio as needed\n",
    "\n",
    "plt.title('HbA1c vs BMI by Age Group')\n",
    "plt.xlabel('HbA1c')\n",
    "plt.ylabel('BMI')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a categorical plot in seaborn using the price categories created above\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "g = sns.catplot(x=\"possibility\", y=\"bmiB\", hue=\"age_group\", data=df_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis in frequency of eating chips and HbA1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x = 'chip_frequency', y = 'HbA1c', data = df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "plt.figure(figsize=(50,50))  # Adjust the figure size as needed (50 inches width, 50 inches height)\n",
    "g = sns.catplot(x=\"chip_frequency\", y=\"HbA1c\", hue=\"age_group\", data=df_3)\n",
    "\n",
    "# Define your desired intervals for x-axis ticks\n",
    "desired_intervals = []  # Modify these intervals as needed\n",
    "\n",
    "# Modify x-axis labels using Matplotlib\n",
    "plt.xticks(ticks=desired_intervals, labels=[f'{i}' for i in desired_intervals], rotation=45)\n",
    "\n",
    "# Expand x-axis by setting aspect ratio\n",
    "# plt.gca().set_aspect(1.5)  # Adjust the aspect ratio as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_3['age_group'], bins=20, color='blue')  # Adjust the number of bins as needed\n",
    "plt.xlabel('age_group')\n",
    "plt.ylabel('chip_frequency')\n",
    "plt.title('Age Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "data_size = 10\n",
    "age_groups = ['Kids(5-13)','teens or older(13-18J)','toddler(0-5J)']\n",
    "df_3 = pd.DataFrame({\n",
    "    'age_group': np.random.choice(age_groups, data_size),\n",
    "    'chip_frequency': np.random.randint(1, 10, data_size),\n",
    "    'possibility': np.random.rand(data_size) * 100\n",
    "})\n",
    "\n",
    "# Grouping data by age group and calculating mean chip frequency and possibility values\n",
    "grouped_data = df_3.groupby('age_group').mean().reset_index()\n",
    "\n",
    "\n",
    "# Create a dual-axis plot\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plotting chip frequency on the right y-axis\n",
    "sns.barplot(x='age_group', y='chip_frequency', data=grouped_data, ax=ax1, color='blue', alpha=0.7)\n",
    "ax1.set_ylabel('Chip Frequency', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Create a second y-axis for possibility values on the left side\n",
    "ax2 = ax1.twinx()\n",
    "sns.lineplot(x='age_group', y='possibility', data=grouped_data, marker='o', ax=ax2, color='red')\n",
    "ax2.set_ylabel('Possibility of Diabeteas', color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Chip Frequency and Possibility Values by Age Group')\n",
    "plt.xlabel('Age group')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a categorical plot in seaborn using the price categories created above\n",
    "\n",
    "#sns.set(style=\"ticks\")\n",
    "# g = sns.catplot(x=\"HbA1c\", y=\"t_age\", hue=\"bmiB\", data=df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating categorical plot \n",
    "# HbA1c and bmiB fairly related \n",
    "# Even though chip_amount is fairly related chip_frequency is variable needed to nbe consider which is fairly related \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'/Users/arunibandara/Documents/ReDIDA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.to_csv(os.path.join(path, 'df_3'),index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqrXGAl02xQ1"
   },
   "source": [
    "## Children's Health\n",
    "\n",
    "#### Investigate blood levels of HbA1c which is a blood biomarker of blood sugar levels and therefore an indicator of diabetes\n",
    "#### Variables that might be associated are bmiB (body mass index), sex, age2 (sex) and the amount and frequency of eating chips (fq44/ fq44a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zb9bQjb03PpW"
   },
   "source": [
    "# Resources\n",
    "- (1) https://app.gitbook.com/@redi-school-1/s/data-analytics/sql-and-databases\n",
    "- (2) https://app.gitbook.com/@redi-school-1/s/data-analytics/analytical-thinking\n",
    "- (3) https://www.stat.berkeley.edu/users/brill/Stat215b/oct7.pdf\n",
    "- (4) https://www.youtube.com/watch?v=GSk-EEu1zkA (1/2) and https://www.youtube.com/watch?v=i5E2hruuLaQ (2/2)\n",
    "- (5) https://www.youtube.com/watch?v=N00g9Q9stBo&t=3307s\n",
    "- (6) https://www.youtube.com/watch?v=vc1bq0qIKoA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqoEusuOe4Pi"
   },
   "source": [
    "<font color='green'>**Next**\n",
    "- Project\n",
    "- Splunk, PowerBI or Tableau?\n",
    "- Fisher's exact test, ...\n",
    "- supervised vs unsupervised (ML)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/ReDI-School/nrw-data-analytics/blob/main/9_Stackoverflow_Analytical_Thinking.ipynb",
     "timestamp": 1670436230264
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
